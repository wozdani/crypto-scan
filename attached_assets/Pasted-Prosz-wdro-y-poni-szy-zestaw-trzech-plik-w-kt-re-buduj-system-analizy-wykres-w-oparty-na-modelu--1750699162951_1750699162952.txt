ProszÄ™ wdroÅ¼yÄ‡ poniÅ¼szy zestaw trzech plikÃ³w, ktÃ³re budujÄ… system analizy wykresÃ³w oparty na modelu CLIP w projekcie crypto-scan. System ten pozwala na:

trenowanie modelu CLIP na parach (obraz wykresu + opis GPT),

przewidywanie etykiet fazy rynku i typu setupu na podstawie wykresÃ³w,

integracjÄ™ z systemem TJDE (simulate_trader_decision_advanced).

ğŸ“ Struktura plikÃ³w i ich funkcje:
1. clip_model.py â€“ definicja architektury CLIP (ViT-B/32 lub RN50)
python
Kopiuj
Edytuj
from transformers import CLIPProcessor, CLIPModel

class CLIPWrapper:
    def __init__(self, model_name="openai/clip-vit-base-patch32"):
        self.model = CLIPModel.from_pretrained(model_name)
        self.processor = CLIPProcessor.from_pretrained(model_name)

    def encode_image(self, image):
        return self.model.get_image_features(**self.processor(images=image, return_tensors="pt"))

    def encode_text(self, texts):
        return self.model.get_text_features(**self.processor(text=texts, return_tensors="pt", padding=True, truncation=True))

    def similarity(self, image, texts):
        inputs = self.processor(text=texts, images=image, return_tensors="pt", padding=True)
        outputs = self.model(**inputs)
        logits_per_image = outputs.logits_per_image
        return logits_per_image.softmax(dim=1)
2. clip_trainer.py â€“ trening modelu na parach (image + label)
python
Kopiuj
Edytuj
import os
import torch
from PIL import Image
from tqdm import tqdm
from clip_model import CLIPWrapper

def train_clip_on_dataset(dataset_dir="training_data/clip/", epochs=3):
    model = CLIPWrapper()
    image_files = [f for f in os.listdir(dataset_dir) if f.endswith(".png")]

    for epoch in range(epochs):
        print(f"ğŸ§  Epoch {epoch + 1}")
        for img_file in tqdm(image_files):
            label_file = img_file.replace(".png", ".txt")
            try:
                image = Image.open(os.path.join(dataset_dir, img_file)).convert("RGB")
                with open(os.path.join(dataset_dir, label_file), "r") as f:
                    labels = f.read().strip().split("|")
                labels = [label.strip() for label in labels if label.strip()]
                if not labels:
                    continue

                sim = model.similarity(image, labels)
                print(f"{img_file} â†’ {labels[torch.argmax(sim)]} (conf: {sim.max().item():.2f})")
            except Exception as e:
                print(f"âŒ Error processing {img_file}: {e}")
3. clip_predictor.py â€“ uÅ¼ycie wytrenowanego modelu do klasyfikacji nowego wykresu
python
Kopiuj
Edytuj
from clip_model import CLIPWrapper
from PIL import Image

def predict_clip_chart(image_path, candidate_labels):
    model = CLIPWrapper()
    image = Image.open(image_path).convert("RGB")
    probs = model.similarity(image, candidate_labels)
    top_idx = probs.argmax().item()
    return {
        "predicted_label": candidate_labels[top_idx],
        "confidence": round(probs[0][top_idx].item(), 3),
        "raw_scores": {label: round(p.item(), 3) for label, p in zip(candidate_labels, probs[0])}
    }

# Example usage:
if __name__ == "__main__":
    result = predict_clip_chart("training_data/clip/FHEUSDT_20250623_1652.png", [
        "breakout-continuation", "pullback-in-trend", "range-accumulation", "trend-reversal", "consolidation"
    ])
    print(result)
âœ… Co naleÅ¼y zrobiÄ‡:
StworzyÄ‡ folder training_data/clip/ jeÅ›li nie istnieje.

UmieÅ›ciÄ‡ pliki clip_model.py, clip_trainer.py i clip_predictor.py w folderze ai/ lub utils/ (zaleÅ¼nie od organizacji).

Do requirements.txt dodaÄ‡:

nginx
Kopiuj
Edytuj
transformers
torchvision
Pillow
UpewniÄ‡ siÄ™, Å¼e Å›rodowisko ma GPU (opcjonalnie) oraz dostÄ™p do Internetu (dla openai/clip-vit-base-patch32).

PÃ³Åºniej moÅ¼liwa bÄ™dzie integracja do simulate_trader_decision_advanced() w formie:

chart_phase_prediction = predict_clip_chart(image_path, CANDIDATE_PHASES)

uwzglÄ™dnienie tej predykcji jako element scoringu (np. jako clip_predicted_phase_modifier)

DziÄ™ki temu, system TJDE otrzyma zupeÅ‚nie nowÄ… warstwÄ™ predykcyjnÄ… â€“ widzenie wykresÃ³w jak profesjonalny trader! ğŸ’¹ğŸ§ 

Daj znaÄ‡, jak tylko zostanie wdroÅ¼one â€“ mogÄ™ pomÃ³c z dalszÄ… integracjÄ… lub testami predykcji na realnych danych.